{
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "DTHEYLk8tBPm",
    "M_1uFvgItH4a"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fa00a23b329948a4bbf354a341b2effe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0426d74a61344a4ebd7c5956fd291775",
       "IPY_MODEL_21e6a3ea843444868c0520e189c2dfbf",
       "IPY_MODEL_7e90b8db3690478fadb7c2c7bdd5748e"
      ],
      "layout": "IPY_MODEL_7337e38c1cb74b30bb44344a398fd8dc"
     }
    },
    "0426d74a61344a4ebd7c5956fd291775": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d940a2e59da419d8aff8d5ffc72debe",
      "placeholder": "​",
      "style": "IPY_MODEL_fa4556aaf1dd4ab6b909d2ada8049f9b",
      "value": "100%"
     }
    },
    "21e6a3ea843444868c0520e189c2dfbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b30f057f0be431d9adf4f7b6ccac0bb",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9738254afe4142d3ac7dcdf2f64bd9f7",
      "value": 2
     }
    },
    "7e90b8db3690478fadb7c2c7bdd5748e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0c5435e4a2e4ffe9b03a3f94ad35cb8",
      "placeholder": "​",
      "style": "IPY_MODEL_f57bed5e885d4dc7aee1bca9341a2995",
      "value": " 2/2 [00:00&lt;00:00, 22.71it/s]"
     }
    },
    "7337e38c1cb74b30bb44344a398fd8dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d940a2e59da419d8aff8d5ffc72debe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4556aaf1dd4ab6b909d2ada8049f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b30f057f0be431d9adf4f7b6ccac0bb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9738254afe4142d3ac7dcdf2f64bd9f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0c5435e4a2e4ffe9b03a3f94ad35cb8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f57bed5e885d4dc7aee1bca9341a2995": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de5507b37d32441e87de3b420d4b5781": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01e898a2de1c4da0a8ebf0efa7ac626a",
       "IPY_MODEL_ec99c88022d44da38a370f0b37be6ced",
       "IPY_MODEL_4fa96e52a03948c4b76281855dc54803"
      ],
      "layout": "IPY_MODEL_7bafc407ef014ed8baaf20e6fbef576c"
     }
    },
    "01e898a2de1c4da0a8ebf0efa7ac626a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c428fc8c0f84333b79c4278e2441b47",
      "placeholder": "​",
      "style": "IPY_MODEL_280f07816c384c96867578d98f8d500d",
      "value": "100%"
     }
    },
    "ec99c88022d44da38a370f0b37be6ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_682f647271bf45c6af459c1472be8d72",
      "max": 144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d6c578fac954c1987c84cd9c289ef35",
      "value": 144
     }
    },
    "4fa96e52a03948c4b76281855dc54803": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2cdfb10eb824c28bd0f8918f3abf69d",
      "placeholder": "​",
      "style": "IPY_MODEL_bf04bf2d4dce4a1bbe73e3d6e6b4d7d8",
      "value": " 144/144 [00:00&lt;00:00, 511.60ex/s]"
     }
    },
    "7bafc407ef014ed8baaf20e6fbef576c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c428fc8c0f84333b79c4278e2441b47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "280f07816c384c96867578d98f8d500d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "682f647271bf45c6af459c1472be8d72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d6c578fac954c1987c84cd9c289ef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2cdfb10eb824c28bd0f8918f3abf69d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf04bf2d4dce4a1bbe73e3d6e6b4d7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Package install",
   "metadata": {
    "id": "e76Widdi4ZCF"
   }
  },
  {
   "cell_type": "code",
   "source": "# install Hugging Face Libraries\n! pip install -q datasets\n! pip install transformers -U\n! pip install transformers[torch] -U\n! pip install sentencepiece\n! pip install evaluate\n! pip install bert_score\n! pip install -U accelerate\n! pip install -q -U bitsandbytes\n! pip install peft\n! pip install wandb",
   "metadata": {
    "id": "CIEB6APFqaMA",
    "outputId": "572e8293-8128-4293-9bfe-fa1805c41d90",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:32:35.400936Z",
     "iopub.execute_input": "2023-09-12T05:32:35.401303Z",
     "iopub.status.idle": "2023-09-12T05:34:49.317051Z",
     "shell.execute_reply.started": "2023-09-12T05:32:35.401269Z",
     "shell.execute_reply": "2023-09-12T05:34:49.315766Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nCollecting transformers\n  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\nSuccessfully installed transformers-4.33.1\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.33.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.0.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.0.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.33.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.16.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.3.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2023.7.22)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=3.0.0->bert_score) (2023.9.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting peft\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.33.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->peft) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nInstalling collected packages: peft\nSuccessfully installed peft-0.5.0\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from huggingface_hub import notebook_login\n\nnotebook_login()",
   "metadata": {
    "id": "dq5uDgwEb98Y",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n# Process Dataset\n\n\n",
   "metadata": {
    "id": "daliM-Z9rL7p"
   }
  },
  {
   "cell_type": "code",
   "source": "dataset_id = \"minh21/cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent\"",
   "metadata": {
    "id": "LIGspDANQGjg",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:34:49.785630Z",
     "iopub.execute_input": "2023-09-12T05:34:49.786539Z",
     "iopub.status.idle": "2023-09-12T05:34:49.791148Z",
     "shell.execute_reply.started": "2023-09-12T05:34:49.786502Z",
     "shell.execute_reply": "2023-09-12T05:34:49.790192Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load your dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)"
   ],
   "metadata": {
    "id": "QXjoXMD4rU2g",
    "outputId": "ea02a4b7-a98d-4a64-9e1c-ced072a9ae3a",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:34:49.794054Z",
     "iopub.execute_input": "2023-09-12T05:34:49.794713Z",
     "iopub.status.idle": "2023-09-12T05:34:57.588852Z",
     "shell.execute_reply.started": "2023-09-12T05:34:49.794676Z",
     "shell.execute_reply": "2023-09-12T05:34:57.587928Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading and preparing dataset parquet/minh21--cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent to /root/.cache/huggingface/datasets/parquet/minh21--cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent-ac2d90590f20e1a2/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdfe20dff3a14702903f3e32b18f82a6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/150k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a84b9ac9cef468f938475a37f6a09e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/24.8k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535f464a472e48939a535248b3c4b139"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/26.2k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ec0e64a1db846e2882e6366daec756f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa44620d87a249a69a22498cd871776d"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/minh21--cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent-ac2d90590f20e1a2/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77c967070c64486ab5018bf1da8d06c0"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "validation_dataset = dataset[\"validation\"]"
   ],
   "metadata": {
    "id": "ZnrHBFzGrdHq",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:34:57.590423Z",
     "iopub.execute_input": "2023-09-12T05:34:57.591245Z",
     "iopub.status.idle": "2023-09-12T05:34:57.596174Z",
     "shell.execute_reply.started": "2023-09-12T05:34:57.591208Z",
     "shell.execute_reply": "2023-09-12T05:34:57.595299Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "validation_dataset",
   "metadata": {
    "id": "L0Wc0fVlrfvS",
    "outputId": "927caf89-66d0-4a73-eef7-612c9e54fb44",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:34:57.597513Z",
     "iopub.execute_input": "2023-09-12T05:34:57.598357Z",
     "iopub.status.idle": "2023-09-12T05:34:57.611964Z",
     "shell.execute_reply.started": "2023-09-12T05:34:57.598322Z",
     "shell.execute_reply": "2023-09-12T05:34:57.611069Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dataset({\n    features: ['title', 'id', 'question', 'answer_text', 'answer_start', 'context'],\n    num_rows: 104\n})"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/flan-t5-large\"\n",
    "# model_id=\"facebook/bart-large\"\n",
    "# Load tokenizer of FLAN-t5-large\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "max_length = 512\n",
    "max_target_length = 200"
   ],
   "metadata": {
    "id": "0XXbPU-HrlRr",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:34:57.613235Z",
     "iopub.execute_input": "2023-09-12T05:34:57.613490Z",
     "iopub.status.idle": "2023-09-12T05:35:02.422790Z",
     "shell.execute_reply.started": "2023-09-12T05:34:57.613467Z",
     "shell.execute_reply": "2023-09-12T05:35:02.421820Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "897ebe8612e648949d3b39ba29ebd491"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec5a40c6d64944fc965f847e3bf6b40f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7dd8d787ce74685959cc02c9220ed38"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fa1a710897f41c58c20754bd53352c7"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# def tokenize(batch):\n",
    "#     inputs = tokenizer(f\"[CONTEXT]: {batch['context']} \\n [QUESTION]: {batch['question']}\" , padding= True, truncation = True, max_length = max_length, return_tensors='pt')\n",
    "#     targets = tokenizer(batch['answer_text'], padding= True, truncation = True, max_length = max_length, return_tensors='pt')\n",
    "#     inputs['labels'] = targets['input_ids']\n",
    "#     return inputs\n",
    "def tokenize(batch):\n",
    "    input = f\"\"\"question: {batch['question']} \\n context: {batch['context']}\"\"\"\n",
    "    inputs = tokenizer(input, truncation=True, max_length=max_length)\n",
    "    targets = tokenizer(batch[\"answer_text\"], truncation=True, max_length=max_length)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs"
   ],
   "metadata": {
    "id": "tlEoRgDHroes",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:02.424399Z",
     "iopub.execute_input": "2023-09-12T05:35:02.425013Z",
     "iopub.status.idle": "2023-09-12T05:35:02.433539Z",
     "shell.execute_reply.started": "2023-09-12T05:35:02.424976Z",
     "shell.execute_reply": "2023-09-12T05:35:02.431032Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=train_dataset.column_names\n",
    ")\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=test_dataset.column_names\n",
    ")\n",
    "tokenized_validation_dataset = validation_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=test_dataset.column_names\n",
    ")"
   ],
   "metadata": {
    "id": "1ev7zDhNsCm3",
    "outputId": "388ee59c-1744-4199-9be6-bbbe2e4b9ccf",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:02.434909Z",
     "iopub.execute_input": "2023-09-12T05:35:02.435316Z",
     "iopub.status.idle": "2023-09-12T05:35:03.709543Z",
     "shell.execute_reply.started": "2023-09-12T05:35:02.435283Z",
     "shell.execute_reply": "2023-09-12T05:35:03.708686Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/884 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9f55027c38a4974acc19daa439d3ea3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/109 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9513d859f5444882a0fa52691f8d82a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/104 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f92144ad64fa4450b2c6c42e1b16d0e3"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "tokenized_validation_dataset[0]",
   "metadata": {
    "id": "8-cUa9MbB3mj",
    "outputId": "2214ac42-d700-40d2-96ab-ef3401238e09",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:03.713876Z",
     "iopub.execute_input": "2023-09-12T05:35:03.714158Z",
     "iopub.status.idle": "2023-09-12T05:35:03.732836Z",
     "shell.execute_reply.started": "2023-09-12T05:35:03.714133Z",
     "shell.execute_reply": "2023-09-12T05:35:03.731930Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "execution_count": 10,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'input_ids': [822,\n  10,\n  571,\n  307,\n  405,\n  8,\n  3607,\n  4874,\n  52,\n  240,\n  58,\n  2625,\n  10,\n  13836,\n  9627,\n  49,\n  19,\n  612,\n  147,\n  477,\n  5,\n  13836,\n  5011,\n  277,\n  54,\n  1137,\n  11905,\n  1951,\n  11,\n  1221,\n  225,\n  36,\n  4260,\n  28,\n  28542,\n  757,\n  11208,\n  12,\n  10558,\n  175,\n  1951,\n  117,\n  164,\n  174,\n  12,\n  1099,\n  6264,\n  1222,\n  8,\n  1868,\n  21,\n  16,\n  10061,\n  124,\n  5,\n  156,\n  1221,\n  33,\n  14327,\n  321,\n  307,\n  18,\n  2708,\n  53,\n  11,\n  710,\n  18,\n  2708,\n  53,\n  23139,\n  7,\n  6,\n  8,\n  1357,\n  81,\n  84,\n  20029,\n  12,\n  36,\n  4874,\n  1271,\n  166,\n  225,\n  36,\n  3,\n  30187,\n  3,\n  390,\n  30,\n  1035,\n  892,\n  6,\n  2550,\n  533,\n  18730,\n  7,\n  6,\n  11,\n  1868,\n  11633,\n  5,\n  2747,\n  1267,\n  24,\n  147,\n  12051,\n  1020,\n  19,\n  2123,\n  28,\n  307,\n  18,\n  2708,\n  53,\n  4537,\n  7,\n  5,\n  86,\n  3607,\n  4874,\n  52,\n  6,\n  1428,\n  23139,\n  57,\n  460,\n  12,\n  5743,\n  13,\n  166,\n  6742,\n  3,\n  99,\n  906,\n  6,\n  258,\n  1428,\n  57,\n  335,\n  12,\n  7580,\n  334,\n  239,\n  5,\n  389,\n  677,\n  13,\n  8,\n  3607,\n  4874,\n  52,\n  19,\n  787,\n  666,\n  5,\n  3,\n  2092,\n  8,\n  166,\n  239,\n  16,\n  8,\n  3607,\n  4874,\n  52,\n  6,\n  220,\n  5170,\n  4709,\n  13,\n  3,\n  8886,\n  630,\n  3,\n  6857,\n  2777,\n  5453,\n  1593,\n  927,\n  107,\n  3274,\n  3,\n  17485,\n  3,\n  21357,\n  308,\n  3,\n  6848,\n  13,\n  1640,\n  5453,\n  3,\n  6857,\n  17251,\n  5453,\n  3,\n  226,\n  3,\n  7256,\n  1593,\n  927,\n  107,\n  5,\n  37,\n  8697,\n  1444,\n  17166,\n  21,\n  8,\n  3607,\n  4874,\n  52,\n  19,\n  3479,\n  5453,\n  3,\n  6857,\n  17251,\n  5453,\n  3,\n  226,\n  3,\n  5268,\n  1593,\n  927,\n  107,\n  21,\n  239,\n  3547,\n  604,\n  5453,\n  3,\n  6857,\n  17251,\n  5453,\n  3,\n  226,\n  9266,\n  1593,\n  927,\n  107,\n  21,\n  239,\n  6180,\n  627,\n  5453,\n  3,\n  6857,\n  1593,\n  927,\n  107,\n  21,\n  239,\n  6464,\n  627,\n  5453,\n  3,\n  6857,\n  1593,\n  2122,\n  107,\n  21,\n  239,\n  3,\n  23440,\n  6,\n  627,\n  5453,\n  3,\n  6857,\n  1593,\n  4950,\n  21,\n  239,\n  505,\n  9169,\n  5,\n  9078,\n  3607,\n  4874,\n  1007,\n  227,\n  239,\n  850,\n  11,\n  164,\n  1099,\n  3,\n  8886,\n  630,\n  3,\n  5705,\n  627,\n  5453,\n  209,\n  2,\n  357,\n  7022,\n  41,\n  15731,\n  5453,\n  61,\n  4394,\n  1444,\n  5,\n  1],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'labels': [147, 477, 1]}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "first_context_decoded = tokenizer.decode(\n",
    "    tokenized_train_dataset[0][\"input_ids\"], skip_special_tokens=True\n",
    ")\n",
    "print(first_context_decoded)"
   ],
   "metadata": {
    "id": "9qnBYPYosI8N",
    "outputId": "e89cf1f2-ccb2-4021-e310-05380896f822",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:03.734483Z",
     "iopub.execute_input": "2023-09-12T05:35:03.735345Z",
     "iopub.status.idle": "2023-09-12T05:35:13.300838Z",
     "shell.execute_reply.started": "2023-09-12T05:35:03.735285Z",
     "shell.execute_reply": "2023-09-12T05:35:13.299822Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "question: What is the purpose of Opioid Taper Decision Tool? context: The Opioid Taper Decision Tool is designed to assist Primary Care providers in determining if an opioid taper is necessary for a specific patient, in performing the taper, and in providing follow-up and support during the taper.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "train_dataset[0]",
   "metadata": {
    "id": "ZPE62M5csMC_",
    "outputId": "e229df07-8f0b-4673-ed33-06f4f7443889",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:13.302354Z",
     "iopub.execute_input": "2023-09-12T05:35:13.303740Z",
     "iopub.status.idle": "2023-09-12T05:35:13.312599Z",
     "shell.execute_reply.started": "2023-09-12T05:35:13.303702Z",
     "shell.execute_reply": "2023-09-12T05:35:13.311640Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'title': 'Features and overview',\n 'id': 0,\n 'question': 'What is the purpose of Opioid Taper Decision Tool?',\n 'answer_text': 'assist Primary Care providers in determining if an opioid taper is necessary for a specific patient, in performing the taper, and in providing follow-up and support during the taper',\n 'answer_start': 46,\n 'context': 'The Opioid Taper Decision Tool is designed to assist Primary Care providers in determining if an opioid taper is necessary for a specific patient, in performing the taper, and in providing follow-up and support during the taper.'}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Fine-tune and evaluate FLAN-T5",
   "metadata": {
    "id": "WlNMSRVOsaHi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/flan-t5-large\"\n",
    "checkpoint = \"flant5-large-lora\"\n",
    "username = \"espiusedwards\"\n",
    "\n",
    "# load model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True, device_map=\"auto\")"
   ],
   "metadata": {
    "id": "TfNjxMYJsjC5",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:35:13.314291Z",
     "iopub.execute_input": "2023-09-12T05:35:13.316893Z",
     "iopub.status.idle": "2023-09-12T05:36:01.233920Z",
     "shell.execute_reply.started": "2023-09-12T05:35:13.316857Z",
     "shell.execute_reply": "2023-09-12T05:36:01.232980Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20ee02c851244a5fb30f147d8d1268cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45703b6cddc74380b17f88982979a689"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a8d0ae7f4434608a845928a3e174b73"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=24,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "# model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "id": "7pSq3zXUWjOL",
    "outputId": "b294e520-aeb2-4e74-c6c1-81c8c680062f",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:36:01.235630Z",
     "iopub.execute_input": "2023-09-12T05:36:01.236020Z",
     "iopub.status.idle": "2023-09-12T05:36:03.408405Z",
     "shell.execute_reply.started": "2023-09-12T05:36:01.235985Z",
     "shell.execute_reply": "2023-09-12T05:36:03.407360Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "trainable params: 7,077,888 || all params: 790,227,968 || trainable%: 0.8956767270479599\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ],
   "metadata": {
    "id": "H1DJDqaqXI0Y",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:36:03.409850Z",
     "iopub.execute_input": "2023-09-12T05:36:03.410401Z",
     "iopub.status.idle": "2023-09-12T05:36:03.583274Z",
     "shell.execute_reply.started": "2023-09-12T05:36:03.410366Z",
     "shell.execute_reply": "2023-09-12T05:36:03.582217Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "bleu_metrics = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids, pred_ids = pred\n",
    "\n",
    "    pred_ids[pred_ids == -100] = tokenizer.pad_token_id\n",
    "    predictions = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    references = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    squad_predictions = [\n",
    "        {\"prediction_text\": answer, \"id\": str(id)}\n",
    "        for id, answer in enumerate(predictions)\n",
    "    ]\n",
    "    squad_references = [\n",
    "        {\n",
    "            \"answers\": {\"answer_start\": [-1], \"text\": [answer]},\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "        for id, answer in enumerate(references)\n",
    "    ]\n",
    "    results = {}\n",
    "    results[\"squad\"] = squad_metric.compute(\n",
    "        predictions=squad_predictions, references=squad_references\n",
    "    )\n",
    "\n",
    "    results[\"bleu\"] = bleu_metrics.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-12T05:36:03.584843Z",
     "iopub.execute_input": "2023-09-12T05:36:03.585180Z",
     "iopub.status.idle": "2023-09-12T05:36:11.350021Z",
     "shell.execute_reply.started": "2023-09-12T05:36:03.585147Z",
     "shell.execute_reply": "2023-09-12T05:36:11.349036Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30e4122b1a4a4b15b6cd6d84db2ae56f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e671c80d1ee84fe8b3c60d578c60b3e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c93c2a658f1b415b89f39555db5b4e67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ed5ae5574fa4269b665035ccfcbf5f3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aff7d4afe0ab4989a3e810a200946bb8"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "output_dir = f\"./{checkpoint}\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,  # higher learning rate\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\",\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"wandb\",\n",
    "    generation_max_length=max_target_length,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset.with_format(\"torch\"),\n",
    "    eval_dataset=tokenized_validation_dataset.with_format(\"torch\"),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ],
   "metadata": {
    "id": "ZArCVGUMXNdy",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:36:11.351503Z",
     "iopub.execute_input": "2023-09-12T05:36:11.352535Z",
     "iopub.status.idle": "2023-09-12T05:36:17.389788Z",
     "shell.execute_reply.started": "2023-09-12T05:36:11.352500Z",
     "shell.execute_reply": "2023-09-12T05:36:17.388792Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train model\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "Vj18rc8KX9CV",
    "outputId": "1fa60e03-ecf7-4d48-d970-d33bd86225ed",
    "execution": {
     "iopub.status.busy": "2023-09-12T05:36:17.391213Z",
     "iopub.execute_input": "2023-09-12T05:36:17.391654Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.push_to_hub(\n",
    "    \"espiusedwards/flant5-large-lora\",\n",
    "    use_auth_token=True,\n",
    "    commit_message=\"fix evaluation, r = 24, 3 epoch\",\n",
    "    private=True,\n",
    "    create_pr=1,\n",
    ")"
   ],
   "metadata": {
    "id": "LRPTbtlGcXJa",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "metadata": {
    "id": "xtzT-Dq_jPvv",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # Save our LoRA model & tokenizer results\n",
    "# peft_model_id=\"results\"\n",
    "# trainer.model.save_pretrained(peft_model_id)\n",
    "# tokenizer.save_pretrained(peft_model_id)\n",
    "# # if you want to save the base model to call\n",
    "# trainer.model.base_model.save_pretrained(peft_model_id)"
   ],
   "metadata": {
    "id": "r2QQmKDzeCNB",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Evaluate",
   "metadata": {
    "id": "Iep2_6YNfckT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "def evaluate_qa(predicted_result):\n",
    "\n",
    "    squad_metric = evaluate.load(\"squad\")\n",
    "    predictions = [\n",
    "        {\"prediction_text\": answer, \"id\": str(id)}\n",
    "        for id, answer in enumerate(predicted_result[\"output\"])\n",
    "    ]\n",
    "    references = [\n",
    "        {\n",
    "            \"answers\": {\n",
    "                \"answer_start\": [ds[\"answer_start\"]],\n",
    "                \"text\": [ds[\"answer_text\"]],\n",
    "            },\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "        for id, ds in enumerate(predicted_result)\n",
    "    ]\n",
    "    results = {}\n",
    "    results[\"squad\"] = squad_metric.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    predictions = predicted_result[\"output\"]\n",
    "    references = predicted_result[\"answer_text\"]\n",
    "\n",
    "    bleu_metrics = evaluate.load(\"bleu\")\n",
    "    results[\"bleu\"] = bleu_metrics.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    bertscore_metric = evaluate.load(\"bertscore\")\n",
    "    berscore = bertscore_metric.compute(\n",
    "        predictions=predictions, references=references, lang=\"en\"\n",
    "    )\n",
    "    results[\"bertscore\"] = {\n",
    "        \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "        \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "        \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "    }\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "checkpoint_model = trainer.model",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Evaluate from checkpoint\nfrom transformers import AutoTokenizer\nfrom peft import AutoPeftModelForSeq2SeqLM\n\nmodel_checkpoint = f\"{username}/{checkpoint}\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, device_map=\"auto\")\ncheckpoint_model = AutoPeftModelForSeq2SeqLM.from_pretrained(\n    model_checkpoint, device_map=\"auto\"\n)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\n\n\ndef interfere_prompt(ds):\n    qa_input = f\"question: {ds['question']} \" f\"context: {ds['context']}\"\n    input_ids = tokenizer(\n        qa_input,\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_length,\n    ).input_ids.to(torch.device(\"cuda\"))\n    outputs = checkpoint_model.generate(\n        input_ids=input_ids, max_new_tokens=max_target_length\n    )\n    ds[\"output\"] = tokenizer.decode(outputs[0]).split(\">\")[1].split(\"<\")[0].strip()\n    return ds\n\n\ncheckpoint_model.eval()\nwith torch.no_grad():\n    predicted_result = dataset[\"test\"].map(interfere_prompt, batched=False)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "evaluate_qa(predicted_result)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load adapters from hub\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_model_id = \"espiusedwards/flant5-large-lora\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    config.base_model_name_or_path, load_in_8bit=True, device_map={\"\": 0}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\": 0})\n",
    "model.eval()\n",
    "\n",
    "print(\"Peft model loaded\")"
   ],
   "metadata": {
    "id": "PfH0EvSGe5Z1",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Other Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(\"cuda\")\n",
    "predictions_for_squad = []\n",
    "predictions_for_squad_v2 = []\n",
    "predictions_for_bert_score = []\n",
    "references_for_bert_score = []\n",
    "for data in test_dataset:\n",
    "    context = data[\"context\"]\n",
    "    question = data[\"question\"]\n",
    "    answer = data[\"answer_text\"]\n",
    "    id = data[\"id\"]\n",
    "    input = f\"\"\"\n",
    "    Read this and answer the question. If the question is unanswerable, \"say \\\"unanswerable\\\".\\n\\n{question}\\n\\n{context}\"\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(\n",
    "        input,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "\n",
    "    model_output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "        )[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    predictions_for_squad.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_squad_v2.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"no_answer_probability\": 0,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_bert_score.append(model_output)\n",
    "    references_for_bert_score.append(answer)\n",
    "    # predictions.extend(predicted_texts)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "references_for_squad_v2 = [\n    {\n        \"answers\": {\"answer_start\": [ds[\"answer_start\"]], \"text\": [ds[\"answer_text\"]]},\n        \"id\": str(ds[\"id\"]),\n    }\n    for id, ds in enumerate(test_dataset)\n]",
   "metadata": {
    "id": "XO9rR80-MQhG",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from evaluate import load\n",
    "\n",
    "results = dict()\n",
    "squad_metric = load(\"squad_v2\")\n",
    "results[\"squad_v2\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad_v2, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results[\"squad\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "bleu_metrics = load(\"bleu\")\n",
    "results[\"bleu\"] = bleu_metrics.compute(\n",
    "    predictions=predictions_for_bert_score, references=references_for_bert_score\n",
    ")\n",
    "\n",
    "bertscore_metric = load(\"bertscore\")\n",
    "berscore = bertscore_metric.compute(\n",
    "    predictions=predictions_for_bert_score,\n",
    "    references=references_for_bert_score,\n",
    "    lang=\"en\",\n",
    ")\n",
    "\n",
    "results[\"bertscore\"] = {\n",
    "    \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "    \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "    \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "}\n",
    "results"
   ],
   "metadata": {
    "id": "Dr8ulytQL4g_",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Too small loss => Validation check on train dataset",
   "metadata": {
    "id": "DTHEYLk8tBPm"
   }
  },
  {
   "cell_type": "code",
   "source": "# validation set\nvalidation_dataset = train_dataset.select(range(100))\nvalidation_dataset",
   "metadata": {
    "id": "1D602sa46wc8",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(\"cuda\")\n",
    "predictions_for_squad = []\n",
    "predictions_for_squad_v2 = []\n",
    "predictions_for_bert_score = []\n",
    "references_for_bert_score = []\n",
    "for data in validation_dataset:\n",
    "    context = data[\"context\"]\n",
    "    question = data[\"question\"]\n",
    "    answer = data[\"answer_text\"]\n",
    "    id = data[\"id\"]\n",
    "    input = f\"\"\"\n",
    "    Read this and answer the question. If the question is unanswerable, \"say \\\"unanswerable\\\".\\n\\n{context}\\n\\n{question}\"\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(\n",
    "        input,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "\n",
    "    model_output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "        )[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    predictions_for_squad.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_squad_v2.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"no_answer_probability\": 0,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_bert_score.append(model_output)\n",
    "    references_for_bert_score.append(answer)\n",
    "    # predictions.extend(predicted_texts)"
   ],
   "metadata": {
    "id": "6Ro8578R7GuH",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "references_for_squad_v2 = [\n    {\n        \"answers\": {\"answer_start\": [ds[\"answer_start\"]], \"text\": [ds[\"answer_text\"]]},\n        \"id\": str(ds[\"id\"]),\n    }\n    for id, ds in enumerate(validation_dataset)\n]",
   "metadata": {
    "id": "rspz9sgJ7OH-",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from evaluate import load\n",
    "\n",
    "results = dict()\n",
    "squad_metric = load(\"squad_v2\")\n",
    "results[\"squad_v2\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad_v2, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results[\"squad\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "bleu_metrics = load(\"bleu\")\n",
    "results[\"bleu\"] = bleu_metrics.compute(\n",
    "    predictions=predictions_for_bert_score, references=references_for_bert_score\n",
    ")\n",
    "\n",
    "bertscore_metric = load(\"bertscore\")\n",
    "berscore = bertscore_metric.compute(\n",
    "    predictions=predictions_for_bert_score,\n",
    "    references=references_for_bert_score,\n",
    "    lang=\"en\",\n",
    ")\n",
    "\n",
    "results[\"bertscore\"] = {\n",
    "    \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "    \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "    \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "}\n",
    "results"
   ],
   "metadata": {
    "id": "sXu43JD27SBA",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Draft - Try functions",
   "metadata": {
    "id": "M_1uFvgItH4a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# import evaluate\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# # Load the model and tokenizer\n",
    "# model = T5ForConditionalGeneration.from_pretrained('espiusedwards/flant5-large-lora')\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small') # adjust model size if necessary\n",
    "# model.eval()\n",
    "\n",
    "# # Load the metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# # Assuming `test_data` is your test data\n",
    "# # and test_data is a list of dictionaries with 'question', 'context', and 'id' keys\n",
    "\n",
    "# # Get predictions\n",
    "# predictions = []\n",
    "# for i in range(len(tokenized_test_dataset)):\n",
    "#     item = tokenized_test_dataset[i]\n",
    "#     inputs = {'input_ids': item['input_ids'], 'attention_mask': item['attention_mask']}\n",
    "#     outputs = model.generate(**inputs, max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "#     prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     predictions.append({'prediction_text': prediction, 'id': item['id']})\n",
    "\n",
    "# references = [{'answers': {'answer_start': [0], 'text': [item['answer']]}, 'id': item['id']} for item in tokenized_test_dataset]\n",
    "\n",
    "# # Compute the metric\n",
    "# result = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# # Display the result\n",
    "# print(result)"
   ],
   "metadata": {
    "id": "LN4lCBZ3qHBq",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # evaluate\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "# from datasets import load_from_disk\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# def evaluate_peft_model(sample,max_target_length=50):\n",
    "#     # generate summary\n",
    "#     outputs = model.generate(input_ids=sample[\"input_ids\"].unsqueeze(0).cuda(), do_sample=True, top_p=0.9, max_new_tokens=max_target_length)\n",
    "#     prediction = tokenizer.decode(outputs[0].detach().cpu().numpy(), skip_special_tokens=True)\n",
    "#     # decode eval sample\n",
    "#     # Replace -100 in the labels as we can't decode them.\n",
    "#     labels = np.where(sample['labels'] != -100, sample['labels'], tokenizer.pad_token_id)\n",
    "#     labels = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     # Some simple post-processing\n",
    "#     return prediction, labels\n",
    "\n",
    "# # dataset: test_dataset\n",
    "\n",
    "# # run predictions\n",
    "# # this can take ~45 minutes\n",
    "# predictions, references = [] , []\n",
    "# for sample in tqdm(test_dataset):\n",
    "#     p,l = evaluate_peft_model(sample)\n",
    "#     predictions.append(p)\n",
    "#     references.append(l)\n",
    "\n",
    "# # compute metric\n",
    "# squad_v2 = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# # print results\n",
    "# print(f\"Exact: {squad_v2['exact']}\")\n",
    "# print(f\"f1: {squad_v2['f1']}\")"
   ],
   "metadata": {
    "id": "Qxl81xZDfVGB",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# from huggingface_hub import HfFolder\n# from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n# # Hugging Face repository id\n# repository_id = f\"{model_id.split('/')[1]}-{dataset_id}\"\n# # Define training args\n# training_args = Seq2SeqTrainingArguments(\n#     output_dir=repository_id,\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n#     predict_with_generate=True,\n#     fp16=False, # Overflows with fp16\n#     learning_rate=5e-5,\n#     num_train_epochs=5,\n#     # logging & evaluation strategies\n#     logging_dir=f\"{repository_id}/logs\",\n#     logging_strategy=\"steps\",\n#     logging_steps=500,\n#     evaluation_strategy=\"epoch\",\n#     save_strategy=\"epoch\",\n#     save_total_limit=2,\n#     load_best_model_at_end=True,\n#     # metric_for_best_model=\"overall_f1\",\n#     # push to hub parameters\n#     report_to=\"tensorboard\",\n#     push_to_hub=False,\n#     hub_strategy=\"every_save\",\n#     #hub_model_id=repository_id,\n#     hub_token=HfFolder.get_token(),\n# )",
   "metadata": {
    "id": "sSx85AbT6ZvZ",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute metric\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "\n",
    "#     # Convert predictions and labels to the format expected by squad_v2 metric\n",
    "#     predictions = [{'prediction_text': pred, 'id': i} for i, pred in enumerate(preds)]\n",
    "#     references = [{'answers': {'answer_start': [0], 'text': [label]}, 'id': i} for i, label in enumerate(labels)]\n",
    "\n",
    "#     result = metric.compute(predictions=predictions, references=references)\n",
    "#     return result"
   ],
   "metadata": {
    "id": "pFliRKs14woL",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute metric\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     # Replace -100 in the labels as we can't decode them.\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "#     return result"
   ],
   "metadata": {
    "id": "yqcebRpR-EAq",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# # Create Trainer instance\n# trainer = Seq2SeqTrainer(\n#     model=model,\n#     args=training_args,\n#     data_collator=data_collator,\n#     train_dataset=tokenized_train_dataset,\n#     eval_dataset=tokenized_test_dataset,\n#     compute_metrics=compute_metrics,\n# )",
   "metadata": {
    "id": "iQ4Hbuq98qw1",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Start training\n",
    "# trainer.train()"
   ],
   "metadata": {
    "id": "f193Be-G_Cs3",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}