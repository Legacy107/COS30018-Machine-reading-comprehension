{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e76Widdi4ZCF"
   },
   "source": [
    "# Package install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIEB6APFqaMA",
    "outputId": "572e8293-8128-4293-9bfe-fa1805c41d90",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# install Hugging Face Libraries\n",
    "! pip install -q datasets\n",
    "! pip install -q transformers -U\n",
    "! pip install -q transformers[torch] -U\n",
    "! pip install -q sentencepiece\n",
    "! pip install -q evaluate\n",
    "! pip install -q bert_score\n",
    "! pip install -q -U accelerate\n",
    "! pip install -q -U bitsandbytes\n",
    "! pip install -q peft\n",
    "! pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dq5uDgwEb98Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daliM-Z9rL7p"
   },
   "source": [
    "\n",
    "# Process Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIGspDANQGjg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_id = \"minh21/cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXjoXMD4rU2g",
    "outputId": "ea02a4b7-a98d-4a64-9e1c-ced072a9ae3a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "# dataset = dataset.remove_columns([\"title\", \"id\"])\n",
    "dataset = dataset.rename_column(\"answer_text\", \"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnrHBFzGrdHq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "validation_dataset = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0Wc0fVlrfvS",
    "outputId": "927caf89-66d0-4a73-eef7-612c9e54fb44",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XXbPU-HrlRr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/flan-t5-large\"\n",
    "checkpoint = \"flant5-large-lora\"\n",
    "username = \"espiusedwards\"\n",
    "# model_id=\"facebook/bart-large\"\n",
    "# Load tokenizer of FLAN-t5-large\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "max_length = 512\n",
    "max_target_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "def evaluate_qa(predicted_result):\n",
    "\n",
    "    squad_metric = evaluate.load(\"squad\")\n",
    "    predictions = [\n",
    "        {\"prediction_text\": answer, \"id\": str(id)}\n",
    "        for id, answer in enumerate(predicted_result[\"output\"])\n",
    "    ]\n",
    "    references = [\n",
    "        {\n",
    "            \"answers\": {\"answer\": [ds[\"answer\"]], \"text\": [ds[\"answer\"]]},\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "        for id, ds in enumerate(predicted_result)\n",
    "    ]\n",
    "    results = {}\n",
    "    results[\"squad\"] = squad_metric.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    predictions = predicted_result[\"output\"]\n",
    "    references = predicted_result[\"answer\"]\n",
    "\n",
    "    bleu_metrics = evaluate.load(\"bleu\")\n",
    "    results[\"bleu\"] = bleu_metrics.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    bertscore_metric = evaluate.load(\"bertscore\")\n",
    "    berscore = bertscore_metric.compute(\n",
    "        predictions=predictions, references=references, lang=\"en\"\n",
    "    )\n",
    "    results[\"bertscore\"] = {\n",
    "        \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "        \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "        \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evluate Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, device_map=\"auto\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_token = 0\n",
    "item_with_tokens_size_larger_than_limit = []\n",
    "for data in train_dataset:\n",
    "    text = data[\"context\"] + \"\\n\" + data[\"question\"]\n",
    "    l = tokenizer(text)[\"input_ids\"].__len__()\n",
    "    if l >= 512:\n",
    "        item_with_tokens_size_larger_than_limit.append(data)\n",
    "    if l >= max_token:\n",
    "        max_token = l\n",
    "\n",
    "print(max_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def interfere(ds):\n",
    "    ds[\"input\"] = (\n",
    "        f\"context: {dataset['train'][0]['context']} \"\n",
    "        + f\"question: {dataset['train'][0]['question']} \"\n",
    "        + f\"answer: {dataset['train'][0]['answer']}\\n\"\n",
    "        + f\"context: {ds['context']} \"\n",
    "        + f\"question: {ds['question']} \"\n",
    "        + f\"answer: \"\n",
    "    )\n",
    "    input_ids = tokenizer(\n",
    "        ds[\"input\"],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    ).input_ids.to(torch.device(\"cuda\"))\n",
    "    outputs = model.generate(input_ids, max_new_tokens=max_target_length)\n",
    "    ds[\"output\"] = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return ds\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_result = dataset[\"test\"].map(interfere, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_qa(predicted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlEoRgDHroes",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def tokenize(batch):\n",
    "#     inputs = tokenizer(f\"[CONTEXT]: {batch['context']} \\n [QUESTION]: {batch['question']}\" , padding= True, truncation = True, max_length = max_length, return_tensors='pt')\n",
    "#     targets = tokenizer(batch['answer'], padding= True, truncation = True, max_length = max_length, return_tensors='pt')\n",
    "#     inputs['labels'] = targets['input_ids']\n",
    "#     return inputs\n",
    "def tokenize(batch):\n",
    "    input = f\"question: {batch['question']} \" f\"context: {batch['context']}\"\n",
    "    inputs = tokenizer(input, truncation=True, max_length=max_length)\n",
    "    targets = tokenizer(batch[\"answer\"], truncation=True, max_length=max_length)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ev7zDhNsCm3",
    "outputId": "388ee59c-1744-4199-9be6-bbbe2e4b9ccf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=train_dataset.column_names\n",
    ")\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=test_dataset.column_names\n",
    ")\n",
    "tokenized_validation_dataset = validation_dataset.map(\n",
    "    tokenize, batched=False, remove_columns=test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-cUa9MbB3mj",
    "outputId": "2214ac42-d700-40d2-96ab-ef3401238e09",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_validation_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qnBYPYosI8N",
    "outputId": "e89cf1f2-ccb2-4021-e310-05380896f822",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_context_decoded = tokenizer.decode(\n",
    "    tokenized_train_dataset[0][\"input_ids\"], skip_special_tokens=True\n",
    ")\n",
    "print(first_context_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPE62M5csMC_",
    "outputId": "e229df07-8f0b-4673-ed33-06f4f7443889",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Compute Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "bleu_metrics = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids, pred_ids = pred\n",
    "\n",
    "    pred_ids[pred_ids == -100] = tokenizer.pad_token_id\n",
    "    predictions = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    references = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    squad_predictions = [\n",
    "        {\"prediction_text\": answer, \"id\": str(id)}\n",
    "        for id, answer in enumerate(predictions)\n",
    "    ]\n",
    "    squad_references = [\n",
    "        {\n",
    "            \"answers\": {\"answer_start\": [-1], \"text\": [answer]},\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "        for id, answer in enumerate(references)\n",
    "    ]\n",
    "    results = {}\n",
    "    results[\"squad\"] = squad_metric.compute(\n",
    "        predictions=squad_predictions, references=squad_references\n",
    "    )\n",
    "\n",
    "    results[\"bleu\"] = bleu_metrics.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlNMSRVOsaHi"
   },
   "source": [
    "# Fine-tune and evaluate FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfNjxMYJsjC5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_id=\"google/flan-t5-large\"\n",
    "# checkpoint = \"flant5-large-lora\"\n",
    "# username = \"espiusedwards\"\n",
    "\n",
    "# load model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pSq3zXUWjOL",
    "outputId": "b294e520-aeb2-4e74-c6c1-81c8c680062f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    r=24,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "# model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1DJDqaqXI0Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZArCVGUMXNdy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "output_dir = f\"./{checkpoint}\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,  # higher learning rate\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\",\n",
    "    predict_with_generate=True,\n",
    "    # report_to=\"wandb\",\n",
    "    generation_max_length=max_target_length,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset.with_format(\"torch\"),\n",
    "    eval_dataset=tokenized_validation_dataset.with_format(\"torch\"),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vj18rc8KX9CV",
    "outputId": "1fa60e03-ecf7-4d48-d970-d33bd86225ed",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRPTbtlGcXJa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\n",
    "    \"espiusedwards/flant5-large-lora\",\n",
    "    use_auth_token=True,\n",
    "    commit_message=\"fix prompt, r = 24, 5 epoch\",\n",
    "    private=True,\n",
    "    create_pr=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtzT-Dq_jPvv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2QQmKDzeCNB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Save our LoRA model & tokenizer results\n",
    "# peft_model_id=\"results\"\n",
    "# trainer.model.save_pretrained(peft_model_id)\n",
    "# tokenizer.save_pretrained(peft_model_id)\n",
    "# # if you want to save the base model to call\n",
    "# trainer.model.base_model.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iep2_6YNfckT"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load adapters from hub\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load peft config for pre-trained checkpoint etc.\n",
    "peft_model_id = \"espiusedwards/flant5-large-lora\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    config.base_model_name_or_path, load_in_8bit=True, device_map={\"\": 0}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\": 0})\n",
    "model.eval()\n",
    "\n",
    "print(\"Peft model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# checkpoint_model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Evaluate from checkpoint\n",
    "from transformers import AutoTokenizer\n",
    "from peft import AutoPeftModelForSeq2SeqLM\n",
    "\n",
    "model_checkpoint = f\"{username}/{checkpoint}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, device_map=\"auto\")\n",
    "checkpoint_model = AutoPeftModelForSeq2SeqLM.from_pretrained(\n",
    "    model_checkpoint, device_map=\"auto\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def interfere_prompt(ds):\n",
    "    qa_input = f\"question: {ds['question']} \" f\"context: {ds['context']}\"\n",
    "    input_ids = tokenizer(\n",
    "        qa_input,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    ).input_ids.to(torch.device(\"cuda\"))\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=max_target_length)\n",
    "    ds[\"output\"] = tokenizer.decode(outputs[0]).split(\">\")[1].split(\"<\")[0].strip()\n",
    "    return ds\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_result = dataset[\"test\"].map(interfere_prompt, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_qa(predicted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(\"cuda\")\n",
    "predictions_for_squad = []\n",
    "predictions_for_squad_v2 = []\n",
    "predictions_for_bert_score = []\n",
    "references_for_bert_score = []\n",
    "for data in test_dataset:\n",
    "    context = data[\"context\"]\n",
    "    question = data[\"question\"]\n",
    "    answer = data[\"answer\"]\n",
    "    id = data[\"id\"]\n",
    "    input = f\"\"\"\n",
    "    Read this and answer the question. If the question is unanswerable, \"say \\\"unanswerable\\\".\\n\\n{question}\\n\\n{context}\"\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(\n",
    "        input,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "\n",
    "    model_output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "        )[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    predictions_for_squad.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_squad_v2.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"no_answer_probability\": 0,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_bert_score.append(model_output)\n",
    "    references_for_bert_score.append(answer)\n",
    "    # predictions.extend(predicted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO9rR80-MQhG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references_for_squad_v2 = [\n",
    "    {\n",
    "        \"answers\": {\"answer_start\": [ds[\"answer_start\"]], \"text\": [ds[\"answer\"]]},\n",
    "        \"id\": str(ds[\"id\"]),\n",
    "    }\n",
    "    for id, ds in enumerate(test_dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr8ulytQL4g_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "results = dict()\n",
    "squad_metric = load(\"squad_v2\")\n",
    "results[\"squad_v2\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad_v2, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results[\"squad\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "bleu_metrics = load(\"bleu\")\n",
    "results[\"bleu\"] = bleu_metrics.compute(\n",
    "    predictions=predictions_for_bert_score, references=references_for_bert_score\n",
    ")\n",
    "\n",
    "bertscore_metric = load(\"bertscore\")\n",
    "berscore = bertscore_metric.compute(\n",
    "    predictions=predictions_for_bert_score,\n",
    "    references=references_for_bert_score,\n",
    "    lang=\"en\",\n",
    ")\n",
    "\n",
    "results[\"bertscore\"] = {\n",
    "    \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "    \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "    \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTHEYLk8tBPm"
   },
   "source": [
    "# Too small loss => Validation check on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1D602sa46wc8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# validation set\n",
    "validation_dataset = train_dataset.select(range(100))\n",
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ro8578R7GuH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(\"cuda\")\n",
    "predictions_for_squad = []\n",
    "predictions_for_squad_v2 = []\n",
    "predictions_for_bert_score = []\n",
    "references_for_bert_score = []\n",
    "for data in validation_dataset:\n",
    "    context = data[\"context\"]\n",
    "    question = data[\"question\"]\n",
    "    answer = data[\"answer\"]\n",
    "    id = data[\"id\"]\n",
    "    input = f\"\"\"\n",
    "    Read this and answer the question. If the question is unanswerable, \"say \\\"unanswerable\\\".\\n\\n{context}\\n\\n{question}\"\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(\n",
    "        input,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(\"cuda\"))\n",
    "\n",
    "    model_output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            input_ids=model_inputs[\"input_ids\"],\n",
    "            attention_mask=model_inputs[\"attention_mask\"],\n",
    "        )[0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    predictions_for_squad.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_squad_v2.append(\n",
    "        {\n",
    "            \"prediction_text\": model_output,\n",
    "            \"no_answer_probability\": 0,\n",
    "            \"id\": str(id),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predictions_for_bert_score.append(model_output)\n",
    "    references_for_bert_score.append(answer)\n",
    "    # predictions.extend(predicted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rspz9sgJ7OH-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references_for_squad_v2 = [\n",
    "    {\n",
    "        \"answers\": {\"answer_start\": [ds[\"answer_start\"]], \"text\": [ds[\"answer\"]]},\n",
    "        \"id\": str(ds[\"id\"]),\n",
    "    }\n",
    "    for id, ds in enumerate(validation_dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXu43JD27SBA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "results = dict()\n",
    "squad_metric = load(\"squad_v2\")\n",
    "results[\"squad_v2\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad_v2, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results[\"squad\"] = squad_metric.compute(\n",
    "    predictions=predictions_for_squad, references=references_for_squad_v2\n",
    ")\n",
    "\n",
    "bleu_metrics = load(\"bleu\")\n",
    "results[\"bleu\"] = bleu_metrics.compute(\n",
    "    predictions=predictions_for_bert_score, references=references_for_bert_score\n",
    ")\n",
    "\n",
    "bertscore_metric = load(\"bertscore\")\n",
    "berscore = bertscore_metric.compute(\n",
    "    predictions=predictions_for_bert_score,\n",
    "    references=references_for_bert_score,\n",
    "    lang=\"en\",\n",
    ")\n",
    "\n",
    "results[\"bertscore\"] = {\n",
    "    \"precision\": sum(berscore[\"precision\"]) / len(berscore[\"precision\"]),\n",
    "    \"recall\": sum(berscore[\"recall\"]) / len(berscore[\"recall\"]),\n",
    "    \"f1\": sum(berscore[\"f1\"]) / len(berscore[\"f1\"]),\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_1uFvgItH4a"
   },
   "source": [
    "# Draft - Try functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LN4lCBZ3qHBq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import evaluate\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# # Load the model and tokenizer\n",
    "# model = T5ForConditionalGeneration.from_pretrained('espiusedwards/flant5-large-lora')\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small') # adjust model size if necessary\n",
    "# model.eval()\n",
    "\n",
    "# # Load the metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# # Assuming `test_data` is your test data\n",
    "# # and test_data is a list of dictionaries with 'question', 'context', and 'id' keys\n",
    "\n",
    "# # Get predictions\n",
    "# predictions = []\n",
    "# for i in range(len(tokenized_test_dataset)):\n",
    "#     item = tokenized_test_dataset[i]\n",
    "#     inputs = {'input_ids': item['input_ids'], 'attention_mask': item['attention_mask']}\n",
    "#     outputs = model.generate(**inputs, max_length=512, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "#     prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     predictions.append({'prediction_text': prediction, 'id': item['id']})\n",
    "\n",
    "# references = [{'answers': {'answer_start': [0], 'text': [item['answer']]}, 'id': item['id']} for item in tokenized_test_dataset]\n",
    "\n",
    "# # Compute the metric\n",
    "# result = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# # Display the result\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qxl81xZDfVGB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # evaluate\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "# from datasets import load_from_disk\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# def evaluate_peft_model(sample,max_target_length=50):\n",
    "#     # generate summary\n",
    "#     outputs = model.generate(input_ids=sample[\"input_ids\"].unsqueeze(0).cuda(), do_sample=True, top_p=0.9, max_new_tokens=max_target_length)\n",
    "#     prediction = tokenizer.decode(outputs[0].detach().cpu().numpy(), skip_special_tokens=True)\n",
    "#     # decode eval sample\n",
    "#     # Replace -100 in the labels as we can't decode them.\n",
    "#     labels = np.where(sample['labels'] != -100, sample['labels'], tokenizer.pad_token_id)\n",
    "#     labels = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     # Some simple post-processing\n",
    "#     return prediction, labels\n",
    "\n",
    "# # dataset: test_dataset\n",
    "\n",
    "# # run predictions\n",
    "# # this can take ~45 minutes\n",
    "# predictions, references = [] , []\n",
    "# for sample in tqdm(test_dataset):\n",
    "#     p,l = evaluate_peft_model(sample)\n",
    "#     predictions.append(p)\n",
    "#     references.append(l)\n",
    "\n",
    "# # compute metric\n",
    "# squad_v2 = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# # print results\n",
    "# print(f\"Exact: {squad_v2['exact']}\")\n",
    "# print(f\"f1: {squad_v2['f1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSx85AbT6ZvZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfFolder\n",
    "# from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "# # Hugging Face repository id\n",
    "# repository_id = f\"{model_id.split('/')[1]}-{dataset_id}\"\n",
    "# # Define training args\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir=repository_id,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     predict_with_generate=True,\n",
    "#     fp16=False, # Overflows with fp16\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     # logging & evaluation strategies\n",
    "#     logging_dir=f\"{repository_id}/logs\",\n",
    "#     logging_strategy=\"steps\",\n",
    "#     logging_steps=500,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     save_total_limit=2,\n",
    "#     load_best_model_at_end=True,\n",
    "#     # metric_for_best_model=\"overall_f1\",\n",
    "#     # push to hub parameters\n",
    "#     report_to=\"tensorboard\",\n",
    "#     push_to_hub=False,\n",
    "#     hub_strategy=\"every_save\",\n",
    "#     #hub_model_id=repository_id,\n",
    "#     hub_token=HfFolder.get_token(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFliRKs14woL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute metric\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "\n",
    "#     # Convert predictions and labels to the format expected by squad_v2 metric\n",
    "#     predictions = [{'prediction_text': pred, 'id': i} for i, pred in enumerate(preds)]\n",
    "#     references = [{'answers': {'answer_start': [0], 'text': [label]}, 'id': i} for i, label in enumerate(labels)]\n",
    "\n",
    "#     result = metric.compute(predictions=predictions, references=references)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqcebRpR-EAq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute metric\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "# # Metric\n",
    "# metric = evaluate.load(\"squad\")\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     # Replace -100 in the labels as we can't decode them.\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ4Hbuq98qw1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Create Trainer instance\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=tokenized_train_dataset,\n",
    "#     eval_dataset=tokenized_test_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f193Be-G_Cs3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "# trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DTHEYLk8tBPm",
    "M_1uFvgItH4a"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e898a2de1c4da0a8ebf0efa7ac626a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c428fc8c0f84333b79c4278e2441b47",
      "placeholder": "​",
      "style": "IPY_MODEL_280f07816c384c96867578d98f8d500d",
      "value": "100%"
     }
    },
    "0426d74a61344a4ebd7c5956fd291775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d940a2e59da419d8aff8d5ffc72debe",
      "placeholder": "​",
      "style": "IPY_MODEL_fa4556aaf1dd4ab6b909d2ada8049f9b",
      "value": "100%"
     }
    },
    "21e6a3ea843444868c0520e189c2dfbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b30f057f0be431d9adf4f7b6ccac0bb",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9738254afe4142d3ac7dcdf2f64bd9f7",
      "value": 2
     }
    },
    "280f07816c384c96867578d98f8d500d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d940a2e59da419d8aff8d5ffc72debe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa96e52a03948c4b76281855dc54803": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2cdfb10eb824c28bd0f8918f3abf69d",
      "placeholder": "​",
      "style": "IPY_MODEL_bf04bf2d4dce4a1bbe73e3d6e6b4d7d8",
      "value": " 144/144 [00:00&lt;00:00, 511.60ex/s]"
     }
    },
    "682f647271bf45c6af459c1472be8d72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d6c578fac954c1987c84cd9c289ef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7337e38c1cb74b30bb44344a398fd8dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b30f057f0be431d9adf4f7b6ccac0bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bafc407ef014ed8baaf20e6fbef576c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e90b8db3690478fadb7c2c7bdd5748e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0c5435e4a2e4ffe9b03a3f94ad35cb8",
      "placeholder": "​",
      "style": "IPY_MODEL_f57bed5e885d4dc7aee1bca9341a2995",
      "value": " 2/2 [00:00&lt;00:00, 22.71it/s]"
     }
    },
    "8c428fc8c0f84333b79c4278e2441b47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9738254afe4142d3ac7dcdf2f64bd9f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2cdfb10eb824c28bd0f8918f3abf69d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf04bf2d4dce4a1bbe73e3d6e6b4d7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de5507b37d32441e87de3b420d4b5781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01e898a2de1c4da0a8ebf0efa7ac626a",
       "IPY_MODEL_ec99c88022d44da38a370f0b37be6ced",
       "IPY_MODEL_4fa96e52a03948c4b76281855dc54803"
      ],
      "layout": "IPY_MODEL_7bafc407ef014ed8baaf20e6fbef576c"
     }
    },
    "e0c5435e4a2e4ffe9b03a3f94ad35cb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec99c88022d44da38a370f0b37be6ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_682f647271bf45c6af459c1472be8d72",
      "max": 144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d6c578fac954c1987c84cd9c289ef35",
      "value": 144
     }
    },
    "f57bed5e885d4dc7aee1bca9341a2995": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa00a23b329948a4bbf354a341b2effe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0426d74a61344a4ebd7c5956fd291775",
       "IPY_MODEL_21e6a3ea843444868c0520e189c2dfbf",
       "IPY_MODEL_7e90b8db3690478fadb7c2c7bdd5748e"
      ],
      "layout": "IPY_MODEL_7337e38c1cb74b30bb44344a398fd8dc"
     }
    },
    "fa4556aaf1dd4ab6b909d2ada8049f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
